---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
library(brolgar)
data(wages_ts)
```
# brolgar (BRowse over Longitudinal data Graphically and Analytically in R) 

Note: This version of brolgar has been forked from [tprvan/brolgar](https://github.com/tprvan/brolgar), and is undergoing breaking changes to the API.
<!-- badges: start -->
[![Travis build status](https://travis-ci.org/njtierney/brolgar.svg?branch=master)](https://travis-ci.org/njtierney/brolgar)
[![AppVeyor build status](https://ci.appveyor.com/api/projects/status/github/njtierney/brolgar?branch=master&svg=true)](https://ci.appveyor.com/project/njtierney/brolgar)
[![Codecov test coverage](https://codecov.io/gh/njtierney/brolgar/branch/master/graph/badge.svg)](https://codecov.io/gh/njtierney/brolgar?branch=master)
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
<!-- badges: end -->

Exploring longitudinal data can be challenging. For example, when there are many individuals it is difficult to look at all of them, as you often get a "plate of spaghetti" plot, with many lines plotted on top of each other. 

```{r show-spaghetti}
library(brolgar)
library(ggplot2)
ggplot(wages_ts, 
       aes(x = xp, 
             y = ln_wages, 
             group = id)) + 
  geom_line()
```

These are hard to interpret. 

You might then want to explore those individuals with higher amounts of variation, or those with lower variation. But calculating this for individuals draws you away from your analysis, and instead you are now wrangling with a different problem: summarising key information about each individual and incorporating that back into the data. 

This is annoying, and distracts from your analysis, inviting errors.

**brolgar** (BRowse over Longitudinal data Graphically and Analytically in R) (forked from https://github.com/tprvan/brolgar)
provides tools for providing statistical summaries for each individual. These are referred to as a **longnostics**, a portmanteau of **long**itudinal and **cognostic**. These **longnostics** make it straightforward to extract subjects with certain properties to gain some insight into the data. 

## Installation

Install from [GitHub](https://github.com/) with:

``` r
# install.packages("remotes")
remotes::install_github("njtierney/brolgar")
```

## What is longitudinal data?

Longitudinal data has subjects who are measured on several characteristics repeatedly through time but not always at the same time points or the same number of times. 

## Longitudinal data is time series data.

One of the **Big Ideas** in `brolgar` is that longitudinal data is a time series.

There is a permanent structure to longitudinal data that should be accounted for. This can be achieved by consider longitudinal data as a type of _time series_ data.

Now, there are many different ways to think about _what your data looks like_. Longitudinal data is often typically called "panel data", for example. I used to always think that "time series" was defined as something that was by definition "regular" - with equal spacings between observations. This is actually not the case - you can have both "regular", and "irregular" time series. Don't believe me? Well, take it up with Professors Rob Hyndman and George Athanasopolous, who say:

> Anything that is observed sequentially over time is a time series. (https://otexts.com/fpp2/data-methods.html)

If we define longitudinal data as a time series, we gain access to a suite of nice tools that simplify and accelerate how we work with time series data.

We can convert longitudinal data into a "**t**ime **s**eries tibble", a `tsibble`, which is built on top of the `tibble` package.

To convert longitudinal data to time series we need to consider:

* What identifies the time component of the data? This is the **index**
* What is the unique identifier of an individual/series? This is the **key**

Together, the **index** and **key** uniquely identify an observation.

What do we mean by this? Let's look at the first section of the wages, **wages** data analysed in Singer & Willett (2003):

```{r slice-wages}
library(dplyr)
slice(wages, 1:10)
```

We have the `id` column, which identifies an individual.

We also have the `exper` column, which identifies the `exper`ience an individual has.

So:

* key: `id`
* index: `exper`

We can specify these things using the `as_tsibble` function from `tsibble`, also stating, `regular = FALSE`, since we have an `irregular` time series.

```{r create-tsibble}
library(tsibble)
wages_ts <- as_tsibble(x = wages,
                       key = id,
                       index = exper,
                       regular = FALSE)
```

This gives us:

```{r print-wages}
wages_ts
```

Note the following information printed at the top:

```
# A tsibble: 6,402 x 9 [!]
# Key:       id [888]
...
```

This says, we have `r nrow(wages_ts)` rows, with `r ncol(wages_ts)` columns. The `!` means that there is no regular spacing between series, and then our "key" is `id`, of which there `r n_keys(wages_ts)`.

The `wages_ts` dataset is actually already made available inside the `brolgar` package, so you won't need to do this.

## Example usage

Let's extract informative individual patterns by concentrating on different statistics. A story can be woven that may be relevant rather than speaking in generalities.

```{r load-and-print}
library(brolgar)
wages_ts
```

### Calculating `features` of longitudinal data

Now that the data is converted to a `tsibble`, we can leverage the power of the `features` family of functions from `feasts` and `fablelite`.

...

### Quick helper functions

* `l_n_obs()` Number of observations
* `l_slope()` Slope and intercept (given some linear model formula)

For example, we can calculate the number of observations with `l_n_obs()`:

```{r example-n-obs}
l_n_obs(wages_ts)
```

Which could be further summarised to get a sense of the range of the data:

```{r summarise-n-obs}
library(ggplot2)
l_n_obs(wages_ts) %>%
ggplot(aes(x = n_obs)) + 
  geom_bar()

l_n_obs(wages_ts) %>% summary()
```

## Identifying an individual of interest

We might be interested in showing the xp and ln_wages, and so look at a plot like the following:

```{r demo-brolgar}
data(wages_ts)
ggplot(wages_ts, 
       aes(x = xp, 
           y = ln_wages, 
           group = id)) + 
  geom_line()
```

This is a plate of spaghetti! It is hard to understand!

We can use `brolgar` to get the number of observations and slope information for each individual to identify those that are decreasing over time.

```{r use-gghighlight}
sl <- l_slope(wages_ts,ln_wages ~ xp)
ns <- l_n_obs(wages_ts)

sl
ns
```

We can then join these summaries back to the data:

```{r show-wages-lg}
wages_lg <- wages_ts %>%
  left_join(sl, by = "id") %>%
  left_join(ns, by = "id")

wages_lg
```

We can then highlight those individuals with more than 5 observations, and highlight those with a negative slope using `gghighlight`:

```{r use-gg-highlight}
library(gghighlight)

wages_lg %>% 
  filter(n_obs > 5) %>%
  ggplot(aes(x = xp, 
             y = ln_wages, 
             group = id)) + 
  geom_line() +
  gghighlight(l_slope_xp < (-0.5),
              use_direct_label = FALSE)
```

## Filtering by the number of observations

You can filter by the number of observations using `filter_n_obs()`

```{r filter-n-obs}

wages_ts %>% filter_n_obs(n_obs > 3)

wages_ts %>% filter_n_obs(n_obs == 1)
```


## Calculating all features

You can calculate all longnostics passing getting all features from brolgar using `feat_brolgar`
```{r show-all-longnostics}
library(fablelite)

wages_ts %>%
  features(xp, feat_brolgar)
```


# A Note on the API

This version of brolgar was been forked from [tprvan/brolgar](https://github.com/tprvan/brolgar), and has undergone breaking changes to the API.

# Further functions in brolgar

There are various summary statistics in `brolgar`, which all start with `b_`.

* `b_min()` Minimum
* `b_max()` Maximum
* `b_mean()` Mean
* `b_diff()` Lagged difference (by default, the first order difference)
* `b_q25()` 25th quartile
* `b_median()` Median value
* `b_q75()` 75th quartile
* `b_sd()` Standard deviation


