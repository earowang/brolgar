---
title: "Stats on Stats: Workflows with Longnostics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Stats on Stats: Workflows with Longnostics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r establish-chunk-opts, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(brolgar)
```

To better understand longitudinal data we can think about some of the exploratory data analysis happening over three datasets:

1. The full data, which contain profiles of the longitudinal observations
2. The longnostics, which contain the longitudinal cognostics for each id
3. The statistics on the longnostics. These are "stats on stats" of longitudinal data.

Let's expand on this.

## The full data

We have the full set of data, which we can look at in "full spaghetti" form like so:

```{r full-spaghetti}
library(ggplot2)
ggplot(wages,
       aes(x = exper,
           y = uerate,
           group = id)) + 
  geom_line()
```

So here we have our data
```{r top-tail}
head(wages)
tail(wages)
```

## The longnostics

Now we can consider the longnostics, just say for example we are only interested in the maximum of `lnw`:

```{r wages-lnw-max}
l_max_wages <- l_max(wages, id, lnw)
```

## The statistics on longnostics

And from here we can explore the longnostics - what is the distribution of the maximum values?

```{r plot-max}
ggplot(l_max_wages,
       aes(x = l_max)) + 
  geom_density()
```

We can get the summary of these:

```{r summary-max}
summary(l_max_wages$l_max)
```

And now we want to identify those individuals who are at, or closest to the quartiles.

```{r summary-max-wages}
l_max_wages_near_quantile <- l_max_wages %>%
  filter(near_quantile(l_max,
                       probs = c(0.25,
                                 0.5,
                                 0.75),
                       tol = 0.01))

```

And now we can join that data back and look at it:

```{r join-them-back}
wages %>%
  inner_join(l_max_wages_near_quantile, by = "id") %>%
  ggplot(aes(x = exper,
             y = lnw,
             group = id)) + 
  geom_line()
```

We notice that we don't see the q75 - this is because we need to add some tolerance around the quantiles so that we can pick up on those values _nearby_

```{r stats-on-stats}
library(purrr)
library(tidyr)
library(brolgar)
library(glue)

l_max_wages <- l_max(wages, id, lnw)

l_max_quants <- quantile(x = l_max_wages[["l_max"]],
                         probs = c(0.25, 0.5, 0.75),
                         type = 7)

part_near <- partial(near,
                     y = l_max_wages[["l_max"]],
                     tol = 0.05)

summarise_l_max_wages <- l_max_wages %>%
  summarise(id = list(id), 
            qs = list(as.list(quantile(x = l_max,
                                       probs = c(0.25, 0.5, 0.75),
                                       type = 7)))
  )

l_max_wages_near <- summarise_l_max_wages %>%
  mutate(is_near = list(map_dfr(flatten(qs), part_near))) %>% 
  select(id, is_near) %>%
  unnest() %>%
  gather(key = "near_q",
         value = "value",
         2:4,
         -id) %>%
  mutate(quant_is_near = case_when(
    value ~ glue::glue("q_{readr::parse_number(near_q)}")
  )) %>%
  filter(!is.na(quant_is_near))

l_max_wages_near
```

```{r show-same}
wages %>%
  inner_join(l_max_wages_near, by = "id") %>%
  ggplot(aes(x = exper,
             y = lnw,
             group = id,
             colour = near_q)) + 
  geom_line() + 
  facet_wrap(~near_q)
```

```{r wages-longnostic-all}

l_wages_all <- longnostic_all(wages,
                              id = id,
                              var = lnw,
                              formula = lnw ~ exper)

l_wages_all %>%
  filter(!is.na(l_slope_exper)) %>%
  select(id, l_slope_exper) %>%
  mutate(q50 = quantile(0.5, type = 7)) %>%
  mutate(near_q50 = near_quantile(x = l_slope_exper,
                                  probs = c(0.5),
                                  tol = 0.001)) %>%
  mutate(dist_q50 = abs(l_slope_exper - quantile(l_slope_exper, 
                                                 probs = 0.5, 
                                                 type = 7))) %>%
  arrange(dist_q50)
```

Let's look at slope.

```{r}
library(dplyr)
wages_slope <- l_slope(wages, id, lnw ~ exper)

b_min <- function(x, ... ) min(x, na.rm = TRUE)
b_max <- function(x, ... ) max(x, na.rm = TRUE)
b_median <- function(x, ... ) median(x, na.rm = TRUE)
b_q1 <- function(x, ... ) quantile(x, type = 7, probs = 0.25, na.rm = TRUE)
b_q3 <- function(x, ... ) quantile(x, type = 7, probs = 0.75, na.rm = TRUE)

library(tidyr)
```

To get the data into the right format, there are a few steps.

First, we need to get the data into a format where we have all the statistics that we are interested in, along with the id, and the statistic of interest.

Like this

```{r}
wages_slope_all_stats <- wages_slope %>%
  mutate_all(.funs = list(min = b_min,
                          max = b_max,
                          median = b_median,
                          q1 = b_q1,
                          q3 = b_q3)) %>%
  select(id,
         starts_with("l_slope"))

wages_slope_all_stats
```

We then need to convert this into long format

```{r}
wages_slope_all_stats_long <- 
wages_slope_all_stats %>%
gather(key = "stat",
         value = "stat_value",
         -id,
         -l_slope_exper)

wages_slope_all_stats_long
```

We can then calculate the difference between each stat and the slope, `l_slope_exper`:
```{r}
stats_diff <- 
wages_slope_all_stats_long %>%
  mutate(stat_diff = abs(l_slope_exper - stat_value))

stats_diff
```

With stats diff, we can then group by the `stat`, and find return those rows with the smallest difference between the statistic and the value:

```{r}
top_stats_diff <- 
stats_diff %>%
  group_by(stat) %>%
  top_n(-1,
        wt = stat_diff)

top_stats_diff
```

```{r}
top_stats_diff %>%
  left_join(wages, by = "id") %>%
  ggplot(aes(x = exper,
             y = lnw,
             group = id,
             colour = stat)) + 
  geom_line()
```


We can then join that back onto the data to show with gghighlight

```{r}
top_stats_diff %>%
  select(id, l_slope_exper, stat) %>%
  right_join(wages, by = "id")
```

These tranformation steps have been compacted into a summary called, `summarise_fivenum()`:

```{r}
summarise_fivenum <- function(data,
                              id,
                              var){

  q_id <- rlang::enquo(id)
  q_var <- rlang::enquo(var)
  
  
data %>%
  mutate_all(.funs = list(min = b_min,
                          max = b_max,
                          median = b_median,
                          q1 = b_q1,
                          q3 = b_q3)) %>%
  select(!!q_id,
         starts_with(rlang::as_label(q_var))) %>%
  gather(key = "stat",
         value = "stat_value",
         -!!q_id,
         -!!q_var) %>%
  mutate(stat_diff = abs(!!q_var - stat_value)) %>%
  group_by(stat) %>%
  top_n(-1,
        wt = stat_diff)
}

```

```{r}
summarise_fivenum(wages_slope,
                  id = id,
                  var = l_slope_exper)
```

